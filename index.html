<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Processamento de Imagem Code Display</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.63.3/codemirror.min.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.63.3/theme/dracula.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="styles.css"> <!-- Link to the external CSS -->
</head>
<body>
    <!-- Header -->
    <header>
        <h1>Processamento de Imagem Code Examples</h1>
        <div class="header-right">
            <button class="toggle-nav-btn" onclick="toggleNav()">Show Navigation</button>
        </div>
    </header>

    <!-- Content Wrapper -->
    <div class="content-wrapper">
        <!-- Side Navigation -->
        <nav id="side-nav" class="hidden">
            <h2>Sections</h2>
            <ul>
                <li><a href="#section-1">Brilho_Contraste_Gama</a></li>
                <li><a href="#section-2">Blur_com_integral_da_imgem</a></li>
                <li><a href="#section-3">Blur_Gaussiano</a></li>
                <li><a href="#section-4">Countor_Image</a></li>
                <li><a href="#section-5">Ruid_Filter_Com_Img_Integral</a></li> 
                <li><a href="#section-6">Sharpening_Filter</a></li>
                <li><a href="#section-7">Segmentação_da_Img_por_Cor</a></li>
                <li><a href="#section-8">Segmentação_da_Img_por_Excentricidade</a></li>
                <li><a href="#section-9">Orientacao_do_Objeto</a></li>
                <li><a href="#section-10">Aruco</a></li>
                <li><a href="#section-11">Transformar_prespectiva_Para_Ler_Aruco</a></li>
                <li><a href="#section-12">Convolução_da_Img_Com_Qualquer_Kernel</a></li>
                <li><a href="#section-13">Xadrez</a></li>
            </ul>
        </nav>

        <!-- Main Content -->
        <div class="main-content" id="main-content">
            <!-- Code Section 1 -->
            <section id="section-1">
                <h2>Brilho_Contraste_Gama</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-1" class="code-area">
import matplotlib.pyplot as plt
import numpy as np

# Brilho
imagem = plt.imread("car.jpg")
imagem = imagem.astype(np.float32)
brilho = 30
imagem_brilho = imagem + brilho
imagem_brilho = np.clip(imagem_brilho, 0, 255)
imagem_brilho = imagem_brilho.astype(np.uint8)

#Contraste
imagem = plt.imread("car.jpg")
imagem = imagem.astype(np.float32)
alpha = 1.5
imagem_contraste = imagem * alpha
imagem_contraste = np.clip(imagem_contraste, 0, 255)
imagem_contraste = imagem_contraste.astype(np.uint8)
                    
#Gama
imagem = plt.imread("car.jpg") #Load the image
imagem = imagem.astype(np.float32) / 255.0  #Normalize to range [0, 1]
gamma = 2.2
imagem_gama = np.power(imagem, gamma) #Apply gamma correction
imagem = (imagem * 255).astype(np.uint8) #Scale back to [0, 255] and convert to uint8
imagem_gama = (imagem_gama * 255).clip(0, 255).astype(np.uint8)

                </textarea>
            </section>

            <!-- Code Section 2 -->
            <section id="section-2">
                <h2>Blur_com_integral_da_imgem</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-2" class="code-area">
import matplotlib.pyplot as plt
import numpy as np

def integral_image(imagem_gray):
    integral_img = np.zeros_like(imagem_gray)

    # Primeiro pixel
    integral_img[0, 0] = imagem_gray[0, 0]

    # Primeira linha
    for j in range(1, imagem_gray.shape[1]):
        integral_img[0, j] = integral_img[0, j-1] + imagem_gray[0, j]

    # Primeira coluna
    for i in range(1, imagem_gray.shape[0]):
        integral_img[i, 0] = integral_img[i-1, 0] + imagem_gray[i, 0]

    # Restantes pixeis 
    for i in range(1, imagem_gray.shape[0]):
        for j in range(1, imagem_gray.shape[1]):
            integral_img[i, j] = imagem_gray[i, j] + integral_img[i-1, j] + integral_img[i, j-1] - integral_img[i-1, j-1]

    return integral_img

def soma_regiao_integral(integral_img, x1, y1, x2, y2):
    total = integral_img[y2, x2]

    if x1 > 0:
        total -= integral_img[y2, x1 - 1]
    if y1 > 0:
        total -= integral_img[y1 - 1, x2]
    if x1 > 0 and y1 > 0:
        total += integral_img[y1 - 1, x1 - 1]

    return total

def blur(imagem_gray, integral_img, window_size):
    blurred_image = np.zeros_like(imagem_gray)
    half_window = window_size // 2

    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            x1 = j - half_window
            if x1 < 0: x1 = 0
            
            y1 = i - half_window
            if y1 < 0: y1 = 0
            
            x2 = j + half_window
            if x2 >= imagem_gray.shape[0]: x2 = imagem_gray.shape[0] - 1
            
            y2 = i + half_window
            if y2 >= imagem_gray.shape[1]: y2 = imagem_gray.shape[1] - 1
                                                                    
            blurred_image[i, j] = soma_regiao_integral(integral_img, x1, y1, x2, y2) / ((x2 - x1 + 1) * (y2 - y1 + 1))

    return blurred_image

imagem = plt.imread("barco.jpg")
height, width  , channel = imagem.shape 
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 
integral_img  = integral_image(imagem_gray)
blurred_img = blur(imagem_gray, integral_img ,30)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Imagem Original")
plt.imshow(imagem)
plt.subplot(1, 3, 2)
plt.imshow(imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale")
plt.subplot(1, 3, 3)
plt.imshow(blurred_img, cmap="gray")
plt.title("Imagem Filtrada")
plt.show() 
                </textarea>
            </section>

            <section id="section-3">
                <h2>Blur_Gaussiano_E_Sharpe_Image</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-3" class="code-area">
import matplotlib.pyplot as plt
import numpy as np
def gaussian(imagem_gray):
    gaussian_matrix = np.array([[1, 4, 6, 4, 1],
                                [4, 16, 24, 16, 4],
                                [6, 24, 36, 26, 6],
                                [4, 16, 24, 16, 4],
                                [1, 4, 6, 4, 1]])

    filtered_img = np.zeros_like(imagem_gray)
    window_height, window_width = gaussian_matrix.shape

    padded_image = np.pad(imagem_gray, 
                            ((window_height // 2, window_height // 2), 
                            (window_width // 2, window_width // 2)),
                            mode='constant', constant_values=0)
    total = np.sum(gaussian_matrix)
    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+window_height, j:j+window_width]
            filtered_img[i, j] = np.sum(window * gaussian_matrix) / total
    
    return filtered_img

def sharpen(imagem_gray):
    # Define the sharpening filter (kernel)
    sharpening_kernel = np.array([[0, -1,  0],
                                    [-1,  5, -1],
                                    [0, -1,  0]])

    filtered_img = np.zeros_like(imagem_gray)
    window_height, window_width = sharpening_kernel.shape

    padded_image = np.pad(imagem_gray, 
                            ((window_height // 2, window_height // 2), 
                            (window_width // 2, window_width // 2)),
                            mode='constant', constant_values=0)

    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+window_height, j:j+window_width]
            
            filtered_img[i, j] = np.sum(window * sharpening_kernel)
    
    return filtered_img

def equation_sharpe(imagem_gray , blurred_img ):
    alpha = 0.5
    return (imagem_gray + alpha*(imagem_gray-blurred_img))

imagem = plt.imread("PCB.jpg")
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 
blurred_img = gaussian(imagem_gray)

#sharpened_img = sharpen(blurred_img)
sharpened_img = equation_sharpe(imagem_gray , blurred_img )

plt.figure(figsize=(16, 8))
plt.subplot(1, 4, 1)
plt.title("Imagem Original")
plt.imshow(imagem)
plt.subplot(1, 4, 2)
plt.imshow(imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale")
plt.subplot(1, 4, 3)
plt.imshow(blurred_img, cmap="gray")
plt.title("Imagem Gaussian Blur")
plt.subplot(1, 4, 4)
plt.imshow(sharpened_img, cmap="gray")
plt.title("Imagem Sharpened")
plt.tight_layout()
plt.show()
                </textarea>
            </section>

            <section id="section-4">
                <h2>Countor_Image</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-4" class="code-area">
# Com Prewitt
import cv2
import numpy as np
import matplotlib.pyplot as plt

imagem = cv2.imread("PCB.jpg") # Load and convert to grayscale
imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)
# Define Prewitt kernels
prewitt_x = np.array([[-1,0,1], 
                      [-1,0,1], 
                      [-1,0,1]])
prewitt_y = np.array([[1, 1, 1], 
                      [0, 0, 0], 
                      [-1,-1,-1]])
# Apply filters
filtered_x = cv2.filter2D(imagem_gray, -1, prewitt_x) # Applies a custom filter or kernel to an image
filtered_y = cv2.filter2D(imagem_gray, -1, prewitt_y)
# Combine the results
contour_img = (np.abs(filtered_x) * 0.5) + (np.abs(filtered_y) * 0.5) #Blends the two images with specified a weight = 0.5
                 
# Com Sobel
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import imread

def apply_sobel_filter(image):
    """
    Aplica o filtro de Sobel a uma imagem.
    :param image: Imagem em escala de cinza como array numpy.
    :return: Magnitude do gradiente após a aplicação do filtro de Sobel.
    """
    # Define os kernels de Sobel
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]])
    sobel_y = np.array([[-1, -2, -1],
                        [ 0,  0,  0],
                        [ 1,  2,  1]])
    
    # Obtém as dimensões da imagem
    h, w = image.shape
    # Cria um array para armazenar o gradiente
    gradient_x = np.zeros_like(image)
    gradient_y = np.zeros_like(image)
    
    # Aplica o filtro de Sobel (evita bordas para simplificar)
    for i in range(1, h-1):
        for j in range(1, w-1):
            region = image[i-1:i+2, j-1:j+2]
            gradient_x[i, j] = np.sum(region * sobel_x)
            gradient_y[i, j] = np.sum(region * sobel_y)
    
    # Calcula a magnitude do gradiente
    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
    magnitude = (magnitude / np.max(magnitude) * 255).astype(np.uint8)  # Normaliza para 0-255
    
    return magnitude

# Carrega a imagem e converte para escala de cinza
image = imread('caminho_para_sua_imagem.jpg')
if image.ndim == 3:  # Caso seja RGB
    image = np.mean(image, axis=2)

# Aplica o filtro de Sobel
sobel_result = apply_sobel_filter(image)

# Mostra os resultados
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Imagem Original')
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('Filtro de Sobel')
plt.imshow(sobel_result, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

                </textarea>
            </section>

            <section id="section-5">
                <h2>Ruid_Filter_Com_Img_Integral</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-5" class="code-area">   
import matplotlib.pyplot as plt
import numpy as np

def integral_image(imagem_gray):
    integral_img = np.zeros_like(imagem_gray)

    # Primeiro pixel
    integral_img[0, 0] = imagem_gray[0, 0]
    
    # Primeira linha
    for j in range(1, imagem_gray.shape[1]):
        integral_img[0, j] = integral_img[0, j-1] + imagem_gray[0, j]

    # Primeira coluna
    for i in range(1, imagem_gray.shape[0]):
        integral_img[i, 0] = integral_img[i-1, 0] + imagem_gray[i, 0]

    # Restantes pixeis 
    for i in range(1, imagem_gray.shape[0]):
        for j in range(1, imagem_gray.shape[1]):
            integral_img[i, j] = imagem_gray[i, j] + integral_img[i-1, j] + integral_img[i, j-1] - integral_img[i-1, j-1]
            
    return integral_img

def soma_regiao_integral(integral_img, x1, y1, x2, y2):
    total = integral_img[y2, x2]
    
    if x1 > 0:
        total -= integral_img[y2, x1 - 1]
    if y1 > 0:
        total -= integral_img[y1 - 1, x2]
    if x1 > 0 and y1 > 0:
        total += integral_img[y1 - 1, x1 - 1]

    return total

def ruid_filter(imagem_gray, integral_img):
    k = int(input("Valor do k? "))
    sz = imagem_gray.shape
    step = int((k - 1) / 2)
    out = np.zeros([sz[0], sz[1]])
    
    for i in range(step, sz[0] + step):
        for j in range(step, sz[1] + step):
            
            x1 = j - step
            if x1 < 0: x1 = 0

            y1 = i - step
            if y1 < 0: y1 = 0

            x2 = j + step
            if x2 >= sz[0]: x2 = sz[0] - 1

            y2 = i + step
            if y2 >= sz[1]: y2 = sz[1] - 1

            region_sum = soma_regiao_integral(integral_img, x1, y1, x2, y2)
            region_area = (x2 - x1 + 1) * (y2 - y1 + 1)
            
            out[i - step, j - step] = region_sum / region_area

    return out 

imagem = plt.imread("barco_with_ruid.jpg")
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 

integral_img  = integral_image(imagem_gray)
filtered_img = ruid_filter(imagem_gray, integral_img)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Imagem Original")
plt.imshow(imagem)
plt.subplot(1, 3, 2)
plt.imshow(imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale")
plt.subplot(1, 3, 3)
plt.imshow(filtered_img, cmap="gray")
plt.title("Imagem Filtrada para o ruido")
plt.show() 
                </textarea>
            </section>

            <section id="section-6">
                <h2>Sharpening_Filter</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-6" class="code-area"> 
import matplotlib.pyplot as plt
import numpy as np

def sharpening_filter(imagem_gray):
    kernel = np.array([[0, -1, 0],
                        [-1, 5, -1],
                        [0, -1, 0]])

    height, width = imagem_gray.shape
    filtered_img = np.zeros_like(imagem_gray)

    for i in range(1, height - 1):
        for j in range(1, width - 1):
            region = imagem_gray[i-1:i+2, j-1:j+2]  
            filtered_img[i, j] = np.clip(np.sum(region * kernel), 0, 255)  
    return filtered_img


imagem = plt.imread("barco.jpg")
imagem_gray= np.mean(imagem,axis=2) #Torna imagem em gray scale 

integral_img  = integral_image(imagem_gray)
filtered_img = sharpening_filter(imagem_gray)

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.title("Imagem Original")
plt.imshow(imagem)
plt.subplot(1, 3, 2)
plt.imshow(imagem_gray, cmap="gray")
plt.title("Imagem em GrayScale")
plt.subplot(1, 3, 3)
plt.imshow(filtered_img, cmap="gray")
plt.title("Imagem Sharpened")
plt.show() 
                </textarea>
            </section> 

            <section id="section-7">
                <h2>Segmentação_da_Img_por_Cor</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-7" class="code-area">
#RGB
                #R                  G                       B 
imagem_hex = (img[:, :, 0] > 90) & (img[:, :, 1] > 90) & (img[:, :, 2] < 50)
imagem_trig = (img[:, :, 0] < 60) & (img[:, :, 1] > 160) & (img[:, :, 2] < 96)
imagem_circ = (img[:, :, 0] < 50) & (img[:, :, 1] < 170) & (img[:, :, 2] > 190)
imagem_quad = (img[:, :, 0] > 190) & (img[:, :, 1] < 50) & (img[:, :, 2] < 50)

#HSV NOTA: Usar apenas CV2 no codigo
"""
Hue (H): Represents the color type (e.g., red, green, blue) and ranges from 0 to 360 degrees (normalized to 0-1 or 0-255 in practice).
    Example: Red is around 0, Green is around 120, and Blue is around 240.

Saturation (S): Represents the intensity of the color and ranges from 0 to 1 (or 0-255). Low saturation means the color is closer to gray.
Value (V): Represents the brightness and ranges from 0 to 1 (or 0-255). High value means brighter colors

Dica: Mexer apenas do H para encontrar a cor depois mexer S e V se for preciso
"""
import cv2
import numpy as np

# Carregando a imagem
img = cv2.imread("photo.jpg")

# Convertendo a imagem de BGR para HSV
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# Definindo os limites de cor para cada máscara em HSV
# Limites para "hex"
lower_hex = np.array([25, 100, 150])   # Example HSV lower bound
upper_hex = np.array([35, 255, 255])  # Example HSV upper bound
imagem_hex = cv2.inRange(hsv_img, lower_hex, upper_hex)

# Limites para "trig"
lower_trig = np.array([40, 100, 150])  # Exemplo de limite inferior
upper_trig = np.array([85, 255, 255])  # Exemplo de limite superior
imagem_trig = cv2.inRange(hsv_img, lower_trig, upper_trig)

# Limites para "circ"
lower_circ = np.array([90, 100, 150])  # Exemplo de limite inferior
upper_circ = np.array([130, 255, 255])  # Exemplo de limite superior
imagem_circ = cv2.inRange(hsv_img, lower_circ, upper_circ)

# Limites para "quad" (Red detection - two ranges)
# Lower red range (0-10)
lower_red1 = np.array([0, 100, 100])
upper_red1 = np.array([10, 255, 255])

# Upper red range (170-180)
lower_red2 = np.array([170, 100, 100])
upper_red2 = np.array([180, 255, 255])

# Apply both red ranges to capture the full red spectrum
imagem_quad1 = cv2.inRange(hsv_img, lower_red1, upper_red1)
imagem_quad2 = cv2.inRange(hsv_img, lower_red2, upper_red2)

# Combine both red ranges using bitwise OR
imagem_quad = cv2.bitwise_or(imagem_quad1, imagem_quad2)

# Exibindo as imagens usando cv2
cv2.imshow("Imagem Original", img)
cv2.imshow("Imagem Hex", imagem_hex)
cv2.imshow("Imagem Trig", imagem_trig)
cv2.imshow("Imagem Circ", imagem_circ)
cv2.imshow("Imagem Quad", imagem_quad)

# Espera por uma tecla e fecha as janelas
cv2.waitKey(0)
cv2.destroyAllWindows()
                </textarea>
            </section> 
            
            <section id="section-8">
                <h2>Segmentação_da_Img_por_Excentricidade</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-8" class="code-area">
import matplotlib.pyplot as plt
import numpy as np
import scipy.ndimage as sc

def get_centroid(imagem):
    M00 = M10 = M01 = 0
    for i in range(imagem.shape[0]):
        for j in range(imagem.shape[1]):
            M00 += imagem[i, j]
            M10 += imagem[i, j] * i
            M01 += imagem[i, j] * j
    
    centroid_i = M10 / M00
    centroid_j = M01 / M00
    return centroid_i, centroid_j

def calcular_orientacao(img):
    centroid_i, centroid_j = get_centroid(img)
    
    mu11 = mu02 = mu20 = 0
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            mu11 += (i - centroid_i) * (j - centroid_j) * img[i, j]
            mu02 += (j - centroid_j) * (j - centroid_j) * img[i, j]
            mu20 += (i - centroid_i) * (i - centroid_i) * img[i, j]
    
    # Calcular a orientação (em radianos)
    theta = 0.5 * np.arctan2(2 * mu11, (mu20 - mu02))
    
    # Calcular Excentricidade
    cov_matrix = np.array([[mu20, mu11], [mu11, mu02]])
    eigenvalues, _ = np.linalg.eig(cov_matrix)
    lambda_max, lambda_min = np.sort(eigenvalues)[::-1]
    excentricidade = np.sqrt(1 - (lambda_min / lambda_max))
    
    return centroid_i, centroid_j, np.degrees(theta), excentricidade

# Carregar a imagem
img = plt.imread("porca_e_parafuso.jpg")

#Segmentacao por cor
img_porca  = (img[:, :, 0] < 80) & (img[:, :, 1] < 85) & (img[:, :, 2] > 150)
img_parafuso = (img[:, :, 0] > 200) & (img[:, :, 1] <65) & (img[:, :, 2] < 60)

img = img_porca + img_parafuso 

"""
# Se for png
img = plt.imread("porca_e_parafuso_red.png")

imagem_gray= np.mean(img,axis=2)

imagem_bin = imagem_gray < 0.6

"""
labeled_img, num_features = sc.label(img)

min_exc= 9999
circ_label = 0
for i in range(1, num_features + 1):
    figure = labeled_img == i
    centroid_i, centroid_j, theata, excentricidade = calcular_orientacao(figure)
    if excentricidade < min_exc:
        circ_label = i
        min_exc = excentricidade
    
plt.subplot(2, 2, 1)
plt.imshow(img)
plt.title("Imagem Original")

plt.subplot(2, 2, 2)
plt.imshow(labeled_img == circ_label)
plt.title("Imagem Circ")

plt.show()
                    
                </textarea>

            </section>   
            <section id="section-9">
                <h2>Orientacao_do_Objeto</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-9" class="code-area">
import matplotlib.pyplot as plt
import numpy as np

# Carregando a imagem
img = plt.imread("photo.jpg")
imagem_los = (img[:, :, 0] > 90) & (img[:, :, 1] > 90) & (img[:, :, 2] < 50)
imagem_trig = (img[:, :, 0] < 60) & (img[:, :, 1] > 160) & (img[:, :, 2] < 96)
imagem_circ = (img[:, :, 0] < 50) & (img[:, :, 1] < 170) & (img[:, :, 2] > 190)
imagem_quad = (img[:, :, 0] > 190) & (img[:, :, 1] < 50) & (img[:, :, 2] < 50)

def get_centroid(imagem):
    M00 = M10 = M01 = 0
    for i in range(imagem.shape[0]):
        for j in range(imagem.shape[1]):
            M00 += imagem[i, j]
            M10 += imagem[i, j] * i
            M01 += imagem[i, j] * j
    
    centroid_i = M10 / M00
    centroid_j = M01 / M00
    return centroid_i, centroid_j

def calcular_orientacao(img):
    centroid_i, centroid_j = get_centroid(img)
    
    mu11 = mu02 = mu20 = 0
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            mu11 += (i - centroid_i) * (j - centroid_j) * img[i, j]
            mu02 += (j - centroid_j) * (j - centroid_j) * img[i, j]
            mu20 += (i - centroid_i) * (i - centroid_i) * img[i, j]
    
    # Calcular a orientação (em radianos)
    theta = 0.5 * np.arctan2(2 * mu11, (mu20 - mu02))
    
    # Calcular Excentricidade
    cov_matrix = np.array([[mu20, mu11], [mu11, mu02]])
    eigenvalues, _ = np.linalg.eig(cov_matrix)
    lambda_max, lambda_min = np.sort(eigenvalues)[::-1]
    excentricidade = np.sqrt(1 - (lambda_min / lambda_max))
    
    return centroid_i, centroid_j, np.degrees(theta), excentricidade

def desenhar_linha(x, y, theta, comprimento=150, cor='red'):
    # Convertendo ângulo para radianos
    theta_rad = np.radians(theta)
    
    # Calculando os componentes de deslocamento da seta (dx, dy)
    dx = comprimento * np.cos(theta_rad)
    dy = -comprimento * np.sin(theta_rad)  # Subtração pois o eixo Y é invertido na imagem
    
    # Desenhando a seta com plt.arrow
    plt.arrow(y, x, dx, dy, head_width=15, head_length=10, fc=cor, ec=cor)

# Calcular os valores para o triângulo (ou outro objeto de interesse)
centroid_i, centroid_j, theta, excentricidade = calcular_orientacao(imagem_trig)

# Exibindo a imagem com a seta orientada
plt.imshow(imagem_trig, cmap='gray')
plt.plot(centroid_j, centroid_i, '*', color='blue')  # Centroid marker
desenhar_linha(centroid_i, centroid_j, theta)  # Desenha a linha de orientação
plt.title("Imagem Circ com Orientação")
plt.show()

# Exibindo o ângulo e excentricidade calculados
print(f"Orientação: {theta:.2f}°")
print(f"Excentricidade do círculo: {excentricidade:.4f}")
                                     
                </textarea>
            </section> 

            <section id="section-10">
                <h2>Aruco</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-10" class="code-area">
"""
O objetivo deste trabalho consiste em identificar os marcadores ARUCo presentes na imagem (imagem 1)  em anexo, através dos seguintes passos:
1 - Segmentar a imagem (extrair pixeis escuros) (imagem 2)
2 - Remover ruído utilizando operadores morfológicos (imagem 3)
3 - Fazer labeling à imagem (identificar os blobs) (imagem 4)
4 - Extrair as subimagens de cada maracador ARUCO através dos valores de área dos blobs (imagem 5)
5 - Para cada marcador, extrair a palavra binária (imagem 6)
6 - Identificar os marcadores através do dicionário seguinte (imagem 7):
        [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1],  # USV
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0],  # ASV
        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0],  # ROV
        [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1],  # AAV
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # UUV
        [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0],  # UAV
"""
import matplotlib.pyplot as plt
import numpy as np
import scipy.ndimage as sc

img = plt.imread("aruco01.png")
img_gray = np.mean(img, axis=2)
img_gray = img_gray < 0.5

img_dil = sc.binary_dilation(img_gray, structure=np.ones([3, 3]))
img_erode = sc.binary_erosion(img_dil, structure=np.ones([7, 7]))
img_final = sc.binary_dilation(img_erode, structure=np.ones([4, 4]))

labeled_img, num_features = sc.label(img_final)


def extrair_aruco(img_final ,labeled_img, num_features):
    excentricidades = []
    rectangular_marker_imgs = []
    bouding_marker_imgs = []


    for k in range(1, num_features + 1):
        M00 = M01 = M10 = 0

        for i in range(labeled_img.shape[0]):
            for j in range(labeled_img.shape[1]):
                M00 += (labeled_img[i, j] == k).astype(int)
                M01 += (labeled_img[i, j] == k).astype(int) * j
                M10 += (labeled_img[i, j] == k).astype(int) * i

        if M00 == 0:  
            continue

        y = M01 / M00 
        x = M10 / M00  

        mu11 = mu02 = mu20 = 0
        for i in range(labeled_img.shape[0]):
            for j in range(labeled_img.shape[1]):
                mu11 += (i - x) * (j - y) * (labeled_img[i, j] == k).astype(int)
                mu02 += (j - y) ** 2 * (labeled_img[i, j] == k).astype(int)
                mu20 += (i - x) ** 2 * (labeled_img[i, j] == k).astype(int)

        cov_matrix = np.array([[mu20, mu11], [mu11, mu02]])
        eigenvalues, _ = np.linalg.eig(cov_matrix)
        lambda_max, lambda_min = np.sort(eigenvalues)[::-1]

        if lambda_max == 0:
            excentricidade = 0
        else:
            excentricidade = np.sqrt(1 - (lambda_min / lambda_max))

        excentricidades.append(excentricidade)
        
        # Ver quais são arucos e defenir excentricade necessaria
        # print("Label = "+ str(k) + " ecc = " + str(excentricidade))
        
        if excentricidade < 0.5 and excentricidade > 0.0:
            rows, cols = np.where(labeled_img == k)
            min_row, max_row = rows.min(), rows.max()
            min_col, max_col = cols.min(), cols.max()
            
            bouding_marker_imgs.append((min_row, max_row , min_col, max_col))
            
            sub_img = img_final[min_row:max_row + 1, min_col:max_col + 1]
            rectangular_marker_imgs.append((sub_img, excentricidade))
            
    return rectangular_marker_imgs,bouding_marker_imgs

rectangular_marker_imgs,bouding_marker_imgs = extrair_aruco(img_final,labeled_img, num_features)


#Ler aruco
def extrair_palavra_binaria(marker_img, grid_size=(6, 6) , inner_size=(4, 4) ):
    """
    Extrai uma representação binária de um marcador ARUCO a partir de uma subimagem.

    Parâmetros:
    marker_img (ndarray): A subimagem do marcador.
    grid_size (tuple): Tamanho da grade externa (6x6 por padrão).
    inner_size (tuple): Tamanho da grade interna (4x4 por padrão).

    Retorna:
    str: Uma string binária representando a área interna 4x4 do marcador.
    """
    rows, cols = marker_img.shape
    cell_height = rows // grid_size[0]
    cell_width = cols // grid_size[1]
    
    # Define as bordas da área 4x4 dentro da 6x6
    start_row = (grid_size[0] - inner_size[0]) // 2
    start_col = (grid_size[1] - inner_size[1]) // 2
    
    word = ""
    for i in range(start_row, start_row + inner_size[0]):
        for j in range(start_col, start_col + inner_size[1]):
            # Extrai uma célula da grade
            cell = marker_img[i*cell_height:(i+1)*cell_height, j*cell_width:(j+1)*cell_width]
            cell_mean = np.mean(cell)
            if cell_mean > 0.6:
                word += "1" 
            else: 
                word += "0"  
    
    return word

markers_dicionary = [
    (np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]), "USV"),
    (np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0]), "ASV"),
    (np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0]), "ROV"),
    (np.array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]), "AAV"),
    (np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), "UUV"),
    (np.array([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]), "UAV")
]

palavras_bins =[]
for i in range(len(rectangular_marker_imgs)):
    (marker_img, ecc) = rectangular_marker_imgs[i]
    
    palavra_bin_str = extrair_palavra_binaria(marker_img)
    print(f"Palavra binaria do marcador {i+1} = {palavra_bin_str}")
    
    palavra_bin = [int(bit) for bit in palavra_bin_str]
    palavras_bins.append(palavra_bin)
    

# Display the original images and processed stages
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
plt.imshow(img)
plt.title("Imagem Original (1)")

plt.subplot(2, 3, 2)
plt.imshow(img_gray)
plt.title("Imagem Binário (2)")

plt.subplot(2, 3, 3)
plt.imshow(img_final)
plt.title("Imagem Sem Ruído")

plt.subplot(2, 3, 4)
plt.imshow(labeled_img)
plt.title("Objetos com Label")

plt.subplot(2, 3, 5)
plt.imshow(img)
for i in range(len(palavras_bins)):
    min_row, max_row , min_col, max_col = bouding_marker_imgs[i]
    
    plt.plot([min_col, max_col, max_col, min_col, min_col], 
            [min_row, min_row, max_row, max_row, min_row], color='red', linewidth=2)
    plt.title(f"Subimagens de cada maracador ARUCO (5)")
    
    for bin_array, marker_name in markers_dicionary:
        if np.array_equal(palavras_bins[i], bin_array):
            plt.text(min_col, min_row, marker_name, color="Black", size=10)
            break 

# Display each extracted rectangular marker
for i in range(len(rectangular_marker_imgs)):
    (marker_img, ecc) = rectangular_marker_imgs[i]
    plt.figure()
    plt.imshow(marker_img)
    plt.title(f"Marcador {i+1} (excentricidade: {ecc:.2f}) (6)")
    plt.axis('off')


plt.tight_layout()
plt.show()
                    
                </textarea>
            </section> 

            <section id="section-11">
                <h2>Transformar_prespectiva_Para_Ler_Aruco</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-11" class="code-area">
import matplotlib.pyplot as plt
import numpy as np
import cv2

def extrair_palavra_binaria(marker_img, grid_size=(8, 8) , inner_size=(6, 6) ):
    """
    Extrai uma representação binária de um marcador ARUCO a partir de uma subimagem.

    Parâmetros:
    marker_img (ndarray): A subimagem do marcador.
    grid_size (tuple): Tamanho da grade externa (6x6 por padrão).
    inner_size (tuple): Tamanho da grade interna (4x4 por padrão).

    Retorna:
    str: Uma string binária representando a área interna 4x4 do marcador.
    """
    if max(marker_img[0]) > 1:   
        marker_img = marker_img / 255
        
    rows, cols = marker_img.shape
    cell_height = rows // grid_size[0]
    cell_width = cols // grid_size[1]
    
    # Define as bordas da área 4x4 dentro da 6x6
    start_row = (grid_size[0] - inner_size[0]) // 2
    start_col = (grid_size[1] - inner_size[1]) // 2
    
    word = ""
    for i in range(start_row, start_row + inner_size[0]):
        for j in range(start_col, start_col + inner_size[1]):
            # Extrai uma célula da grade
            cell = marker_img[i*cell_height:(i+1)*cell_height, j*cell_width:(j+1)*cell_width]
            cell_mean = np.mean(cell)
            if cell_mean < 0.6:
                word += "1" 
            else: 
                word += "0"  
                
            """
            In ArUco Original Image
            A white cell corresponds to a binary 1.
            A black cell corresponds to a binary 0.
            """
    
    return word


def ordenar_pontos(pontos):
    # Calcular o centro dos pontos
    center = np.mean(pontos, axis=0)
    
    # Ordenar os pontos com base na posição relativa ao centro
    sorted_points = sorted(pontos, key=lambda p: (p[0] - center[0]) ** 2 + (p[1] - center[1]) ** 2)
    
    # Reordenar para garantir a sequência correta: top-left, top-right, bottom-left, bottom-right
    # Os 4 pontos ordenados
    top_left = min(sorted_points, key=lambda p: p[0] + p[1])
    top_right = max(sorted_points, key=lambda p: p[0] - p[1])
    bottom_left = min(sorted_points, key=lambda p: p[0] - p[1])
    bottom_right = max(sorted_points, key=lambda p: p[0] + p[1])
    
    return np.array([top_left, top_right, bottom_right, bottom_left], dtype="float32")


img = plt.imread("persp02.png")
img_gray = np.mean(img, axis=2)
img_gray = img_gray < 0.5
img_gray = (img_gray * 255).astype(np.uint8)
countorns,_ = cv2.findContours(img_gray,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
dst_points = np.array([[0, 0], [200, 0], [200, 200], [0, 200]], dtype="float32") # Trocar Pontos se img tiver invertida 
output_size = (200, 200)

fig, ax = plt.subplots()
plt.title("Imagem com Posições Marcadas")
ax.imshow(img)

# Adicionar círculos para as regiões detectadas
i = 1
for cont in countorns:
    # Aproximar o contorno para simplificar a forma
    epsilon = 0.05 * cv2.arcLength(cont, True)
    approx = cv2.approxPolyDP(cont, epsilon, True)
    
    # Adicionar círculos nas posições dos pontos aproximados
    for point in approx:
        x, y = point[0]  # Extrair x e y do ponto
        circle = plt.Circle((x, y), radius=5, color='red', fill=True)
        ax.add_artist(circle)
    
    src_points = np.array([p[0] for p in approx], dtype="float32")
    src_points = ordenar_pontos(src_points)
    
    matriz_formacao = cv2.getPerspectiveTransform(src_points, dst_points)
    transformed_img_gray = cv2.warpPerspective(img_gray, matriz_formacao, output_size)
    
    plt.figure(figsize=(8, 8))
    plt.imshow(transformed_img_gray, cmap='gray')
    plt.title("Imagem Transformada " + str(i))

    word = extrair_palavra_binaria(transformed_img_gray)
    print("Imagem Transformada "  + str(i) + " = " + word)
    
    i = i + 1

plt.show()

                </textarea>
            </section>

            <section id="section-12">
                <h2>Convolução_da_Img_Com_Qualquer_Kernel</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-12" class="code-area">
import numpy as np
import matplotlib.pyplot as plt
import numpy as np

def convolution_color(image_color,kernel):
    
    if image_color.dtype != np.uint8:  # Scale values to 0-255 if necessary
        image_color = (image_color * 255).astype(np.uint8)
    
    
    # Create an empty array for the sharpened image
    sharpened_img = np.zeros_like(image_color, dtype=np.uint8)
    window_height, window_width = kernel.shape

    # Apply the filter to each channel independently
    for channel in range(3):  # Process R, G, B channels
        channel_data = image_color[:, :, channel]
        height, width = channel_data.shape

        # Pad the single channel
        padded_channel = np.pad(channel_data, 
                                ((window_height // 2, window_height // 2), 
                                 (window_width // 2, window_width // 2)),
                                mode='constant', constant_values=0)

        # Perform convolution
        filtered_channel = np.zeros_like(channel_data, dtype=np.float32)
        for i in range(height):
            for j in range(width):
                # Extract a region from the padded image
                region = padded_channel[i:i + window_height, j:j + window_width]
                filtered_channel[i, j] = np.sum(region * kernel)

        # Clip values to the valid range and store in output
        sharpened_img[:, :, channel] = np.clip(filtered_channel, 0, 255)

    return sharpened_img

def convolution_gray(imagem_gray , kernel ):
    
    filtered_img = np.zeros_like(imagem_gray)
    window_height, window_width = kernel.shape

    padded_image = np.pad(imagem_gray, 
                            ((window_height // 2, window_height // 2), 
                            (window_width // 2, window_width // 2)),
                            mode='constant', constant_values=0)

    for i in range(imagem_gray.shape[0]):
        for j in range(imagem_gray.shape[1]):
            window = padded_image[i:i+window_height, j:j+window_width]
            
            filtered_img[i, j] = np.clip(np.sum(window * kernel), 0, 255)
    
    return filtered_img


# Load the image
image = plt.imread("PCB.jpg")

kernel = np.array([[0, -1,  0],
                    [-1,  5, -1],
                    [0, -1,  0]])
 

# Apply the sharpening filter
sharp1 = convolution_color(image,kernel)

imagem_gray= np.mean(image,axis=2)
sharp2 = convolution_gray(imagem_gray,kernel)

# Display the original image
plt.figure()
plt.title("Original Image")
plt.imshow(image)
plt.axis('off')

# Display the sharpened color image
plt.figure()
plt.title("Sharpened Image 1")
plt.imshow(sharp1)
plt.axis('off')

plt.figure()
plt.title("Sharpened Image 2")
plt.imshow(sharp2,cmap="gray")
plt.axis('off')

plt.show()

                </textarea>
            </section>

            <section id="section-13">
                <h2>Xadrez</h2>
                <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
                <textarea id="python-code-13" class="code-area">
import cv2
import glob
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors


def Detetar_cantos(num_images,images):
    cols = 4  # Número de colunas desejado
    rows = (num_images // cols) + (num_images % cols > 0)
    cantos=np.zeros([num_images,4,2])
    for i in range(num_images):
        fname = images[i]
        print('Processing {}'.format(fname))
        
        I = cv2.imread(fname)
        hsv = cv2.cvtColor(I, cv2.COLOR_BGR2HSV)
        Ibw = (hsv[:, :, 1] > 100) * (hsv[:, :, 0] < 70) * (hsv[:, :, 0] > 55) * (I[:, :, 0] > 10) * (I[:, :, 1] > 10)
        Ibw = Ibw.astype(np.uint8) * 255
        
        Ibw = cv2.dilate(Ibw, np.ones((7, 7)))
        Ibw = cv2.erode(Ibw, np.ones((13, 13)))
        colored_image = cv2.cvtColor(Ibw, cv2.COLOR_GRAY2BGR)
        
        # Encontrar contornos
        contornos, _ = cv2.findContours(Ibw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Encontrar o maior contorno
        maior_contorno = max(contornos, key=cv2.contourArea)

        # Desenhar o maior contorno em verde
        I_cantos = I.copy()
        cv2.drawContours(colored_image, [maior_contorno], -1, (0, 255, 0), 25)

        # Aproximar o contorno para encontrar os cantos
        epsilon = 0.1 * cv2.arcLength(maior_contorno, True)
        approx = cv2.approxPolyDP(maior_contorno, epsilon, True)
        
        # Separar pontos superiores e inferiores com base em suas coordenadas y
        pontos = sorted(approx.reshape(4, 2), key=lambda x: x[1])  # Ordenar por y
        pontos_superiores = sorted(pontos[:2], key=lambda x: x[0])  # Ordenar os dois pontos superiores por x
        pontos_inferiores = sorted(pontos[2:], key=lambda x: x[0], reverse=True)  # Ordenar os dois inferiores por x

        # cantos ordenados: superior-esquerdo, superior-direito, inferior-direito, inferior-esquerdo
        cantos_ordenados = np.array(pontos_superiores + pontos_inferiores, dtype="float32")


        cantos[i]=cantos_ordenados
        # Desenhar os cantos do maior contorno
        for ponto in cantos_ordenados:
            x, y = ponto.ravel()
            cv2.circle(colored_image, (int(x), int(y)), 35, (0, 0, 255), -1)

        # Adicionar imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))
        plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return cantos


def get_warped_img(num_images,images,cantos):
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    resolution=50
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    pts_destino = np.array([[0, 0], [warpedSize[1], 0], [warpedSize[1], warpedSize[0]], [0, warpedSize[0]]], dtype='float32')

    M=np.zeros([num_images,3,3])

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem
        I = cv2.imread(fname)
        
        # Calcular a matriz de transformação projetiva
        M[i] = cv2.getPerspectiveTransform(np.array(cantos[i], dtype='float32'), pts_destino)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))
    
        # Adicionar a imagem ao subplot
        plt.subplot(5, 4, i + 1)
        plt.imshow(cv2.cvtColor(warped_image, cv2.COLOR_BGR2RGB))  # Converter de volta para RGB para exibição
        plt.axis('off')
        
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return M


def get_centroids_of_black_squares(num_images,images,M):
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    resolution=50
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    stats_centroides=np.zeros([num_images,2*reducedSquares[0]*reducedSquares[1]-reducedSquares[0]-reducedSquares[1]+1,2])

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem
        I = cv2.imread(fname)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))

        # Segmentação por threshold adaptativo
        gray_warped = warped_image[:, :, 1]
        bw_warped = cv2.adaptiveThreshold(gray_warped, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 111, 1)

        # Centroides dos quadrados pretos
        Iwhite = cv2.dilate(bw_warped, np.ones((9, 9)))  # Dilatar para melhorar a detecção
        Iblack = 255 - Iwhite  # Inverter a imagem binária (para os quadrados brancos se tornarem pretos)

        # Criar uma cópia colorida para desenhar os círculos
        colored_image = cv2.cvtColor(Iwhite, cv2.COLOR_GRAY2BGR)
        
        # Encontrar componentes conectados
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(Iblack)
        
        # Filtrar os quadrados com base em largura e altura
        filtered_centroids = []
        for j in range(1, num_labels):  # Começar de 1 para ignorar o fundo (label 0)
            x, y, w, h, area = stats[j]
            
            # Verificar se a largura e altura estão no intervalo desejado
            if resolution - 20 < w < resolution and resolution - 20 < h < resolution:
                filtered_centroids.append(centroids[j])  # Adicionar os stats do quadrado que atende aos critérios
        
        # Converter a lista de stats filtrados para um array
        stats_centroides[i] = np.array(filtered_centroids)

        for centroid in filtered_centroids:  
            center_x, center_y = centroid  # Usar diretamente as coordenadas (x, y)

            # Desenhar um círculo verde no centroide
            cv2.circle(colored_image, (int(center_x), int(center_y)), 11, (0, 0, 255), -1)  # Círculo preenchido de verde


        # Adicionar a imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))  # Converter de volta para RGB para exibição
        plt.axis('off')
        
    plt.tight_layout()
    plt.show()
    plt.figure()
    
    return stats_centroides

def filtrar_e_ordenar_centroid_com_KNN(num_images,images,M,stats_centroides):
    resolution=50
    molduraThickness=1.5 #1.5 squares
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    grid_rows, grid_cols = reducedSquares[0],reducedSquares[1]
    warped_centroids=np.zeros([num_images,reducedSquares[0]*reducedSquares[1],2])
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)

    # Loop sobre as imagens
    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')

        # Carregar imagem
        I = cv2.imread(fname)

        # Aplicar a transformação para obter a imagem transformada
        warped_image = cv2.warpPerspective(I, M[i], (warpedSize[1], warpedSize[0]))

        # Segmentação por threshold adaptativo
        gray_warped = warped_image[:, :, 1]
        bw_warped = cv2.adaptiveThreshold(gray_warped, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 111, 1)

        # Centroides dos quadrados pretos
        Iwhite = cv2.dilate(bw_warped, np.ones((9, 9)))  # Dilatar para melhorar a detecção
        Iblack = 255 - Iwhite  # Inverter a imagem binária (para os quadrados brancos se tornarem pretos)

        # Criar uma cópia colorida para desenhar os círculos
        colored_image = cv2.cvtColor(Iwhite, cv2.COLOR_GRAY2BGR)


        # Ajustar o modelo KNN com os centroides filtrados
        knn = NearestNeighbors(n_neighbors=1).fit(stats_centroides[i])

        # Desenhar os centroides
        for centroid in stats_centroides[i]:  
            center_x, center_y = centroid  # Usar diretamente as coordenadas (x, y)

            # Desenhar um círculo verde no centroide
            cv2.circle(colored_image, (int(center_x), int(center_y)), 10, (50, 50, 50), -1)  # Círculo preenchido de verde

        # Encontrar limites da grelha
        x_min, y_min = np.min(stats_centroides[i], axis=0)
        x_max, y_max = np.max(stats_centroides[i], axis=0)

        # Definir o espaçamento da grelha
        grid_x_spacing = (x_max - x_min) / (grid_cols - 1)
        grid_y_spacing = (y_max - y_min) / (grid_rows - 1)

        # Gerar nós da grelha
        
        grid_nodes = []
        idx=0
        for row in range(grid_rows):
            for col in range(grid_cols):
                grid_x = int(x_min + col * grid_x_spacing)
                grid_y = int(y_min + row * grid_y_spacing)
                grid_nodes.append([grid_x, grid_y])
                #cv2.circle(colored_image, (grid_x, grid_y), 10, (0, 128, 255), -1)  # Nó da grelha em azul

                # Desenhar linhas verticais (exceto para o último nó de cada coluna)
                if col < grid_cols - 1:
                    next_x = int(x_min + (col+1) * grid_x_spacing)
                    cv2.line(colored_image, (grid_x, grid_y), (next_x, grid_y), (0, 0, 100), 2)

                # Desenhar linhas horizontais (exceto para o último nó de cada linha)
                if row < grid_rows - 1:
                    next_y = int(y_min + (row+1) * grid_y_spacing)
                    cv2.line(colored_image, (grid_x, grid_y), (grid_x, next_y), (0, 0, 100), 2)
                    
                distance, nearest_index = knn.kneighbors([(grid_x, grid_y)])
                nearest_centroid = stats_centroides[i][nearest_index[0][0]]
                
                warped_centroids[i,idx] = nearest_centroid
                idx=idx+1
                
                center_x, center_y = nearest_centroid  # Usar diretamente as coordenadas (x, y)
                cv2.circle(colored_image, (int(center_x), int(center_y)), 11, (0, 0, 255), -1)  # Círculo preenchido de verde

                # Desenhar uma linha conectando o nó da grelha ao centroide mais próximo
                center_x, center_y = nearest_centroid
                cv2.line(colored_image, (grid_x, grid_y), (int(center_x), int(center_y)), (0, 255, 0), 3)


        # Adicionar a imagem ao subplot
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(colored_image, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    # Exibir as imagens com os centroides e a grelha sobrepostos
    plt.tight_layout()
    plt.show()
    plt.figure()

    return warped_centroids


def por_centroids_na_img_original(num_images,images,warped_centroids):
    molduraThickness=1.5 #1.5 squares
    resolution=50
    boardSquares=np.array([15,29])
    warpedSize=np.array([resolution*(boardSquares[0]+2*molduraThickness), resolution*(boardSquares[1]+2*molduraThickness)]).astype(np.int32)
    pts_destino = np.array([[0, 0], [warpedSize[1], 0], [warpedSize[1], warpedSize[0]], [0, warpedSize[0]]], dtype='float32')
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    centroides_reais=np.zeros([num_images,reducedSquares[0]*reducedSquares[1],2])
    
    # Loop sobre as imagens
    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')

        # Carregar imagem
        I = cv2.imread(fname)

        # Transformar os centróides para coordenadas reais usando a matriz de homografia
        c = warped_centroids[i].reshape(warped_centroids[i].shape[0], 1, 2)
        h = cv2.findHomography(pts_destino.astype('float32'), cantos[i].astype('float32'))[0]
        #h = np.linalg.inv(M[i])
        centroides_reais[i] = cv2.perspectiveTransform(c, h).squeeze()

        # Desenhar os centroides reais
        for (x, y) in centroides_reais[i]:
            # Desenhar um círculo em cada centroide
            cv2.circle(I, (int(x), int(y)), 25, (0, 0, 255), -1)  # Círculo verde

        # Mostrar a imagem com os centroides desenhados
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    plt.tight_layout()
    plt.show()
    plt.figure()

    return centroides_reais

def calibarar_camera(num_images,images,centroides_reais):
    boardSquares=np.array([15,29])
    reducedSquares=np.array([int(np.ceil(boardSquares[0]/2)),int(np.ceil(boardSquares[1]/2))])
    camsize = cv2.imread(images[0]).shape
    NY = reducedSquares[0]
    NX = reducedSquares[1]
    objp = np.zeros((NY * NX, 3), np.float32)
    objp[:, :2] = np.mgrid[0:NX, 0:NY].T.reshape(-1, 2)
    imgpoints = [centroides_reais[i].reshape(-1, 1, 2).astype('single') for i in range(len(centroides_reais))]
    objpoints = [objp.astype('single') for i in range(len(centroides_reais))]
    calibration_stop_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 1000, 1e-9)

    # Calibracao da camara
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (camsize[1], camsize[0]), None, None, None, calibration_stop_criteria)
    print(np.array2string(mtx, formatter={'float_kind':lambda x: f"{x:.2f}"}))

    # Calcular matriz da camara optimizada (alpha=0 para manter o máximo do campo de visão sem bordas, alpha=1 para mostrar campo de visão completo)
    mtx_opt0, roi0 = cv2.getOptimalNewCameraMatrix(mtx, dist, (camsize[1], camsize[0]), alpha=0)
    mtx_opt1, roi1 = cv2.getOptimalNewCameraMatrix(mtx, dist, (camsize[1], camsize[0]), alpha=1)

    # Correção das imagens

    for i in range(num_images):
        fname = images[i]
        print(f'Processing {fname}')
        
        # Carregar imagem original
        I = cv2.imread(fname)

        # Corrigir distorção sem corte
        corrI = cv2.undistort(I, mtx, dist, None, mtx_opt1)

        # Mostrar a imagem corrigida
        plt.subplot(rows, cols, i + 1)
        plt.imshow(cv2.cvtColor(corrI, cv2.COLOR_BGR2RGB))
        plt.axis('off')

    plt.tight_layout()
    plt.show()
       

nome = 'calibracao'
images = glob.glob(nome + '/*.jpg')
num_images = len(images)
cols = 4  # Número de colunas desejado
rows = (num_images // cols) + (num_images % cols > 0)  # Calcula o número de linhas

# Passo #0: Ler as imagens
plt.figure()
for i in range(num_images):
    fname = images[i]
    print('Processing {}'.format(fname))
    
    I = cv2.imread(fname)

    # Adicionar imagem ao subplot
    plt.subplot(rows, cols, i + 1)
    plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))
    plt.axis('off')

plt.tight_layout()
plt.show()
plt.figure()

cantos = Detetar_cantos(num_images,images)
M = get_warped_img(num_images,images,cantos)
centroides = get_centroids_of_black_squares(num_images,images,M)
filtered_centroid = filtrar_e_ordenar_centroid_com_KNN(num_images,images,M,centroides)
centroides_reais = por_centroids_na_img_original(num_images,images,filtered_centroid)
calibarar_camera(num_images,images,centroides_reais)
            </textarea>
        </section>

        <section id="section-14">
            <h2>LOG_OR_DOG_Edge_Detection</h2>
            <button class="copy-btn" onclick="copySection(this)">Copy Code</button>
            <textarea id="python-code-14" class="code-area">
import cv2
import numpy as np
import matplotlib.pyplot as plt

def difference_of_gaussians(image, sigma1=1.0, sigma2=2.0):
    
    if image is None:
        raise ValueError("Image not found or invalid file path.")
    
    # Apply Gaussian blurring with different sigma values
    blurred1 = cv2.GaussianBlur(image, (0, 0), sigma1)
    blurred2 = cv2.GaussianBlur(image, (0, 0), sigma2)
    
    # Compute the Difference of Gaussians
    dog_image = cv2.subtract(blurred1, blurred2)
    
    # Normalize to display properly (DOG result can have negative values)
    dog_image = np.uint8(np.absolute(dog_image))
    
    return dog_image


def laplacian_of_gaussian_edge_detection(image, sigma=1.0):
    
    if image is None:
        raise ValueError("Image not found or invalid file path.")
    
    # Apply Gaussian blur to smooth the image
    blurred = cv2.GaussianBlur(image, (0, 0), sigma)
    
    # Apply the Laplacian filter to the blurred image
    log_edges = cv2.Laplacian(blurred, cv2.CV_64F, ksize=3)
    
    # Convert to absolute values (edges can have negative gradients)
    log_edges = np.uint8(np.absolute(log_edges))
    
    return log_edges


# File path to the input image
image_path = "can.jpg"
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# Perform LOG edge detection
sigma = 2.0  # Adjust the sigma for the Gaussian blur
log_edge_image = laplacian_of_gaussian_edge_detection(image, sigma=sigma)

sigma1 = 1.0  # First Gaussian kernel
sigma2 = 2.0 # Second Gaussian kernel
dog_edge_image = difference_of_gaussians(image, sigma1=sigma1, sigma2=sigma2)

# Display the results
plt.figure()
plt.title("Original Image")
plt.imshow(image, cmap="gray")
plt.axis("off")

plt.figure()
plt.title("LOG Edge Detection")
plt.imshow(log_edge_image, cmap="gray")
plt.axis("off")

plt.figure()
plt.title("DOG Edge Detection")
plt.imshow(dog_edge_image, cmap="gray")
plt.axis("off")

plt.show()
                
            </textarea>
        </section>  
        
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.63.3/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.63.3/mode/python/python.min.js"></script>
    <script src="script.js"></script>
</body>
</html>
